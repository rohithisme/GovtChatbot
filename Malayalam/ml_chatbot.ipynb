{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b90d9413",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open /workspace/Malayalam/vector_db/embeddings.faiss for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 161\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [12], line 136\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Initialize chatbot with mBERT model\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     chatbot \u001b[38;5;241m=\u001b[39m \u001b[43mRAGChatbot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/Malayalam/vector_db/embeddings.faiss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/Malayalam/vector_db/metadata.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-multilingual-cased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using mBERT for Malayalam support\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKSR Chatbot initialized with multilingual BERT model. Commands:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to exit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [12], line 14\u001b[0m, in \u001b[0;36mRAGChatbot.__init__\u001b[0;34m(self, index_path, metadata_path, model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_path, metadata_path, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Load FAISS index\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Load metadata\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(metadata_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/faiss/swigfaiss_avx2.py:10538\u001b[0m, in \u001b[0;36mread_index\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m  10537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_index\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m> 10538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_swigfaiss_avx2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open /workspace/Malayalam/vector_db/embeddings.faiss for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.llms import Ollama\n",
    "import textwrap\n",
    "import torch\n",
    "import os\n",
    "torch.cuda.set_device(6)\n",
    "\n",
    "class RAGChatbot:\n",
    "    def __init__(self, index_path, metadata_path, model_name='bert-base-multilingual-cased'):\n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "            \n",
    "        # Initialize embedding model with mBERT for Malayalam language support\n",
    "        print(f\"Loading embedding model: {model_name}\")\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "        \n",
    "        # Initialize Ollama\n",
    "        self.llm = Ollama(model=\"llama3.3:70b-instruct-q8_0\")\n",
    "        \n",
    "        # Initialize conversation history\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def get_relevant_context(self, query, k=6):\n",
    "        # Create query embedding\n",
    "        query_embedding = self.embedder.encode([query])\n",
    "        \n",
    "        # Search in FAISS index\n",
    "        distances, indices = self.index.search(query_embedding.astype('float32'), k)\n",
    "        \n",
    "        # Get relevant texts and their metadata\n",
    "        context = []\n",
    "        for idx in indices[0]:\n",
    "            meta = self.metadata[idx]\n",
    "\n",
    "            # Create a list of field-value pairs, excluding empty values\n",
    "            fields = []\n",
    "            if meta.get('Document'):\n",
    "                fields.append(f\"Document: {meta['Document']}\")\n",
    "            if meta.get('Part'):\n",
    "                fields.append(f\"Part: {meta['Part']}\")\n",
    "            if meta.get('Chapter'):\n",
    "                fields.append(f\"Chapter: {meta['Chapter']}\")\n",
    "            if meta.get('Appendix'):\n",
    "                fields.append(f\"Appendix: {meta['Appendix']}\")\n",
    "            if meta.get('Annexure'):\n",
    "                fields.append(f\"Annexure: {meta['Annexure']}\")\n",
    "            if meta.get('Section'):\n",
    "                fields.append(f\"Section: {meta['Section']}\")\n",
    "            if meta.get('Sub Section'):\n",
    "                fields.append(f\"Sub Section: {meta['Sub Section']}\")\n",
    "            if meta.get('Sub division'):\n",
    "                fields.append(f\"Sub division: {meta['Sub division']}\")\n",
    "            if meta.get('Rule no.'):\n",
    "                fields.append(f\"Rule: {meta['Rule no.']}\")\n",
    "            if meta.get('Amendment order no.'):\n",
    "                fields.append(f\"Amendment Order: {meta['Amendment order no.']}\")\n",
    "            if meta.get('Order date'):\n",
    "                fields.append(f\"Order Date: {meta['Order date']}\")\n",
    "            if meta.get('Effective date'):\n",
    "                fields.append(f\"Effective Date: {meta['Effective date']}\")\n",
    "            if meta.get('Description'):\n",
    "                fields.append(f\"Description: {meta['Description']}\")\n",
    "\n",
    "            # Join all non-empty fields with commas\n",
    "            context_string = ', '.join([f for f in fields if f])\n",
    "            context.append(context_string)\n",
    "        return context\n",
    "    \n",
    "    def generate_response(self, query, context):\n",
    "        # Create prompt with conversation history\n",
    "        conversation_context = \"\\n\".join([\n",
    "            f\"Human: {exchange['query']}\\nAssistant: {exchange['response']}\"\n",
    "            for exchange in self.conversation_history[-3:]  # Include last 3 exchanges\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"You are an expert assistant in Kerala Government Rules like KSR, KFC, KTC, KSSR etc.  \n",
    "Follow these guidelines for your responses:\n",
    "1. Use simple, everyday language that anyone can understand\n",
    "2. Organize your answer in clear paragraphs with one main idea per paragraph\n",
    "3. Start with the most important information first\n",
    "4. Include proper references (document, part, chapter, section, appendix, annexure, rule number, etc.) when available\n",
    "5. Clearly state if the answer cannot be found in the provided rules\n",
    "6. Avoid technical jargon unless absolutely necessary, and explain any technical terms you must use\n",
    "7. Use short sentences and simple sentence structure\n",
    "8. DO NOT fabricate information. If the answer is not found in the rules, explicitly state so.\n",
    "\n",
    "Previous conversation:\n",
    "{conversation_context}\n",
    "\n",
    "Relevant Rules:\n",
    "{' '.join(context)}\n",
    "\n",
    "Current question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "        # Generate response using Ollama\n",
    "        response = self.llm.invoke(prompt)\n",
    "        \n",
    "        # Update conversation history\n",
    "        self.conversation_history.append({\n",
    "            'query': query,\n",
    "            'response': response,\n",
    "            'context': context\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def chat(self, query):\n",
    "        # Handle conversation management commands\n",
    "        if query.lower() == 'clear history':\n",
    "            self.conversation_history = []\n",
    "            return \"Conversation history cleared.\"\n",
    "            \n",
    "        if query.lower() == 'show history':\n",
    "            history = \"\\n\\n\".join([\n",
    "                f\"Human: {exchange['query']}\\nAssistant: {exchange['response']}\"\n",
    "                for exchange in self.conversation_history\n",
    "            ])\n",
    "            return f\"Conversation History:\\n{history}\"\n",
    "        \n",
    "        # Normal query processing\n",
    "        context = self.get_relevant_context(query)\n",
    "        response = self.generate_response(query, context)\n",
    "        return response\n",
    "\n",
    "def main():\n",
    "    # Initialize chatbot with mBERT model\n",
    "    chatbot = RAGChatbot(\n",
    "        '/workspace/Malayalam/vector_db/embeddings.faiss', \n",
    "        '/workspace/Malayalam/vector_db/metadata.json',\n",
    "        model_name='bert-base-multilingual-cased'  # Using mBERT for Malayalam support\n",
    "    )\n",
    "    \n",
    "    print(\"KSR Chatbot initialized with multilingual BERT model. Commands:\")\n",
    "    print(\"- Type 'quit' to exit\")\n",
    "    print(\"- Type 'clear history' to clear conversation history\")\n",
    "    print(\"- Type 'show history' to view conversation history\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if query.lower() == 'quit':\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            response = chatbot.chat(query)\n",
    "            print(\"\\nAssistant:\", textwrap.fill(response, width=80))\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f61db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
